{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import preprocessing\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import cross_validation\n",
    "import xlsxwriter\n",
    "from sklearn import linear_model, grid_search, datasets\n",
    "from operator import itemgetter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haemophilus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Other_disease_WIKI_161_week\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(158, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Other disease Wikipedia Data\n",
    "\n",
    "%cd /home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Other_disease_WIKI_161_week/\n",
    "\n",
    "wiki_train_data = pd.read_csv(\"Haemophilus.csv\")\n",
    "weekly_data = wiki_train_data[21:].groupby(np.arange(len(wiki_train_data[21:]))//7).sum()\n",
    "article_names = ['Haemophilus',\n",
    "'Haemophilus_influenzae',\n",
    "'Gram-negative_bacteria',\n",
    "'Facultative_anaerobic_organism',\n",
    "'Epiglottitis',\n",
    "'Cellulitis',\n",
    "'Meningitis',\n",
    "'Pathogenic_bacteria',\n",
    "'Hib_vaccine',\n",
    "'Osteomyelitis'\n",
    "]\n",
    "selected_wiki_articles = ['Haemophilus','Haemophilus_influenzae','Gram-negative_bacteria',\n",
    "                          'Facultative_anaerobic_organism','Epiglottitis','Hib_vaccine','Osteomyelitis']\n",
    "other_disease_normalized_weekly_wiki_data = pd.DataFrame()\n",
    "for i in weekly_data:\n",
    "    # Create x, where x the 'scores' column's values as floats\n",
    "    x = weekly_data[i].values.astype(float)\n",
    "    # Create a minimum and maximum processor object\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    # Create an object to transform the data to fit minmax processor\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    # Run the normalizer on the dataframe\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    other_disease_normalized_weekly_wiki_data = pd.concat([other_disease_normalized_weekly_wiki_data, df_normalized], axis=1)\n",
    "other_disease_normalized_weekly_wiki_data.columns=article_names\n",
    "other_disease_normalized_weekly_wiki_data = other_disease_normalized_weekly_wiki_data[selected_wiki_articles]\n",
    "other_disease_normalized_weekly_wiki_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Other_Disease_GT_normalized_csv_160_week\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(158, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Other disease Google Trend Dataset\n",
    "\n",
    "%cd /home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Other_Disease_GT_normalized_csv_160_week/\n",
    "gt_train_data = pd.read_csv(\"haemophilus_normalized.csv\",header=None)\n",
    "gt_train_data = gt_train_data[2:]\n",
    "gt_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Flu_WIKI_161_week\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(158, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flu disease Wiki Dataset\n",
    "\n",
    "flu_article_names = ['en-Common_cold',\n",
    "                     'en-Human_flu',\n",
    "                     'en-Influenza',\n",
    "                     'en-Influenza-like_illness',\n",
    "                     'en-Influenza_A_virus',\n",
    "                     'en-Influenza_A_virus_subtype_H1N1',\n",
    "                     'en-Influenzavirus_A',\n",
    "                     'en-Influenzavirus_C',\n",
    "                     'en-Oseltamivir',\n",
    "                     'en-Zanamivir']\n",
    "\n",
    "%cd /home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Flu_WIKI_161_week/\n",
    "flu_wiki_data = pd.read_csv(\"top10_Flu_daily_wiki_data_161_week.csv\")\n",
    "flu_weekly_wiki_data = flu_wiki_data[21:].groupby(np.arange(len(flu_wiki_data[21:]))//7).sum()\n",
    "normalized_flu_weekly = pd.DataFrame()\n",
    "for i in flu_weekly_wiki_data:\n",
    "    # Create x, where x the 'scores' column's values as floats\n",
    "    x = flu_weekly_wiki_data[i].values.astype(float)\n",
    "    # Create a minimum and maximum processor object\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    # Create an object to transform the data to fit minmax processor\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    # Run the normalizer on the dataframe\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    normalized_flu_weekly = pd.concat([normalized_flu_weekly, df_normalized], axis=1)\n",
    "normalized_flu_weekly.columns=flu_article_names\n",
    "normalized_flu_weekly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Flu_GFT_DATA_160_week\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(158, 30)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flu disease Google Flu Trend Dataset\n",
    "\n",
    "%cd /home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/Flu_GFT_DATA_160_week/\n",
    "flu_google_flu_trend_data = pd.read_csv(\"GFT_160week.csv\")\n",
    "flu_google_flu_trend_data = flu_google_flu_trend_data[2:]\n",
    "flu_google_flu_trend_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 50)\n"
     ]
    }
   ],
   "source": [
    "## Combination of all training datasets\n",
    "'''\n",
    "c1 = sp.csr_matrix(other_disease_normalized_weekly_wiki_data)\n",
    "c2 = sp.csr_matrix(gt_train_data)\n",
    "c3 = sp.csr_matrix(normalized_flu_weekly)\n",
    "c4 = sp.csr_matrix(flu_google_flu_trend_data)\n",
    "h = sp.hstack((c1, c2,c3,c4), format='csr')\n",
    "combined_all_datasets = h.A\n",
    "print combined_all_datasets.shape\n",
    "'''\n",
    "\n",
    "\n",
    "combined_all_datasets = pd.DataFrame()\n",
    "other_disease_normalized_weekly_wiki_data = other_disease_normalized_weekly_wiki_data.reset_index()\n",
    "gt_train_data = gt_train_data.reset_index()\n",
    "normalized_flu_weekly = normalized_flu_weekly.reset_index()\n",
    "flu_google_flu_trend_data = flu_google_flu_trend_data.reset_index()\n",
    "combined_all_datasets = pd.concat([other_disease_normalized_weekly_wiki_data, gt_train_data, normalized_flu_weekly, flu_google_flu_trend_data], axis=1)\n",
    "del combined_all_datasets['index']\n",
    "print combined_all_datasets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK\n"
     ]
    }
   ],
   "source": [
    "## Observed Data Set\n",
    "\n",
    "%cd /home/tanlab1/Desktop/MultipleDisease/sonsonson/correlations/combined/LAST_OFFSET_WORK/\n",
    "observation_data = pd.read_csv(\"ALL_OBSERVATION_DATA.csv\")\n",
    "selected_observation_disease = ['Flu', 'Haemophilus']\n",
    "\n",
    "other_disease_normalized_weekly_wiki_data = observation_data[selected_observation_disease]\n",
    "observation_data = observation_data[selected_observation_disease]\n",
    "\n",
    "combined_all_datasets = combined_all_datasets.as_matrix()\n",
    "observation_data = observation_data.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getScore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-940600342e0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_all_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'getScore' is not defined"
     ]
    }
   ],
   "source": [
    "r2,mse,mae,best_scores = getScore(combined_all_datasets, observation_data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-917712534588>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r2' is not defined"
     ]
    }
   ],
   "source": [
    "print r2[0::2]\n",
    "print r2[1::2]\n",
    "print sum(r2[0::2])/len(r2[0::2])\n",
    "print sum(r2[1::2])/len(r2[1::2])\n",
    "\n",
    "print mse[0::2]\n",
    "print mse[1::2]\n",
    "print sum(mse[0::2])/len(mse[0::2])\n",
    "print sum(mse[1::2])/len(mse[1::2])\n",
    "\n",
    "print mae[0::2]\n",
    "print mae[1::2]\n",
    "print sum(mae[0::2])/len(mae[0::2])\n",
    "print sum(mae[1::2])/len(mae[1::2])\n",
    "\n",
    "print best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getScore(X,y, numberOfDisease):\n",
    "    data = X\n",
    "    gt = y\n",
    "    r2 = []\n",
    "    mse = []\n",
    "    mae = []\n",
    "    rep = []\n",
    "    parameters = {\"alpha\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                  \"l1_ratio\": [0, 0.25, 0.5,0.75,1],\n",
    "              \"fit_intercept\": [True],\n",
    "              \"max_iter\":[1000],\n",
    "              \"normalize\":[True, False],\n",
    "              \"selection\":['cyclic', 'random'],\n",
    "              \"tol\":[0.0001, 0.001]}\n",
    "    \n",
    "    #cv = cross_validation.KFold(len(train), n_folds=10, shuffle=True)\n",
    "    #for data,gt in cv:\n",
    "       #print data, gt\n",
    "    s = 0\n",
    "    for random_generator in range(1,11):\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(data, gt, test_size=0.3, random_state=random_generator)\n",
    "        mtl = linear_model.MultiTaskElasticNet()\n",
    "        grid_search = GridSearchCV(mtl, param_grid=parameters, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        predictions = grid_search.predict(X_test)\n",
    "        for i in range(0,numberOfDisease):\n",
    "            s += 1\n",
    "            r2.append(r2_score(y_test[:,i], predictions[:,i]))\n",
    "            mse.append(mean_squared_error(y_test[:,i], predictions[:,i]))\n",
    "            mae.append(mean_absolute_error(y_test[:,i], predictions[:,i]))\n",
    "\n",
    "        temp = report(grid_search.grid_scores_)\n",
    "        rep.append(temp)\n",
    "    return r2, mse, mae, rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(grid_scores, n_top=1):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    l = []\n",
    "    for i, score in enumerate(top_scores):\n",
    "        \n",
    "        #print(\"Model with rank: {0}\".format(i + 1))\n",
    "        #print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "        #     score.mean_validation_score,\n",
    "        #      np.std(score.cv_validation_scores)))\n",
    "        #print(\"Parameters: {0}\".format(score.parameters))\n",
    "        #print(\"\")\n",
    "        l.append(score.mean_validation_score)\n",
    "        l.append(np.std(score.cv_validation_scores))\n",
    "        l.append(score.parameters)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
