{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import urllib2\n",
    "import json\n",
    "import sys\n",
    "import collections\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an new Excel file and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook('Haemophilus.xlsx')\n",
    "worksheet = workbook.add_worksheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(date_text):\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "        raise ValueError(\"Incorrect data format, should be YYYY-MM-DD\")\n",
    "\n",
    "def parser(baslangic_yil, bitis_yil):\n",
    "    #db = MySQLdb.connect(\"localhost\",\"root\",\"5462593180\",\"wiki_twitter_google\")\n",
    "    lines = open('wiki_article_name.txt').read().splitlines()\n",
    "    row = 0\n",
    "    col = 0\n",
    "    temp = 0\n",
    "    for line in lines:\n",
    "        worksheet.write(row,col, str(line))\n",
    "        col = col + 1\n",
    "        temp = col\n",
    "        row = 0\n",
    "        for yil in range(int(baslangic_yil),int(bitis_yil)+1):\n",
    "            for ay in range(1,13):\n",
    "                #print str(ay) + \" \" + str(yil)\n",
    "                url_line = line.replace(\" \",\"%20\")\n",
    "                if ay < 10:\n",
    "                    ay = \"0\" + str(ay)\n",
    "                url = \"http://stats.grok.se/json/en/\"+str(yil)+str(ay)+\"/\"+url_line\n",
    "                page = urllib2.urlopen(url)\n",
    "                soup = BeautifulSoup(page.read())\n",
    "                context = json.loads(soup.get_text() )\n",
    "                day_list = context['daily_views']\n",
    "                if len(day_list) > 0:\n",
    "                    day_list = collections.OrderedDict(sorted(day_list.items()))\n",
    "                    for day in day_list:\n",
    "                        if(validate(day)):\n",
    "                            row += 1\n",
    "                            col = temp\n",
    "                            worksheet.write(row,col,day)\n",
    "                            col += 1\n",
    "                            worksheet.write(row,col,day_list[day])\n",
    "                                #sql = \"INSERT INTO wiki (article_name, date_, view) VALUES ('%s', '%s', '%d')\" % (line,day,day_list[day])\n",
    "                                #cursor.execute(sql)\n",
    "        \n",
    "    workbook.close()\n",
    "\n",
    "    #f = open(sys.argv[1],'r')\n",
    "    #out = f.read().splitlines() # will append in the list out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser(2010,2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
