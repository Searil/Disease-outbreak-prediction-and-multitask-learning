{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import io\n",
      "from IPython.nbformat import current\n",
      "\n",
      "def execute_notebook(nbfile):\n",
      "    \n",
      "    with io.open(nbfile) as f:\n",
      "        nb = current.read(f, 'json')\n",
      "    \n",
      "    ip = get_ipython()\n",
      "    \n",
      "    for cell in nb.worksheets[0].cells:\n",
      "        if cell.cell_type != 'code':\n",
      "            continue\n",
      "        ip.run_cell(cell.input)\n",
      "%cd /home/bbardak/Desktop/gft_wiki/Results/\n",
      "execute_notebook(\"all_methods.ipynb\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/bbardak/Desktop/gft_wiki/Results\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/ground-truth"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(len(ground_truth_data), n_folds=10, shuffle=True)\n",
      "mylist = list(kf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,\n",
        "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  26,  27,\n",
        "        28,  29,  31,  33,  34,  35,  36,  37,  38,  39,  40,  42,  43,\n",
        "        44,  45,  46,  47,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
        "        58,  59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  71,\n",
        "        72,  73,  74,  75,  77,  78,  79,  80,  83,  84,  85,  86,  87,\n",
        "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 101,\n",
        "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
        "       115, 116, 117, 118, 119, 120, 121, 123, 124, 126, 127, 128, 129,\n",
        "       130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143,\n",
        "       144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157]), array([ 12,  25,  30,  32,  41,  48,  65,  76,  81,  82, 100, 122, 125,\n",
        "       139, 149, 156]))\n",
        "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "        14,  15,  16,  17,  19,  20,  22,  23,  25,  28,  29,  30,  31,\n",
        "        32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  45,\n",
        "        46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
        "        59,  60,  61,  63,  65,  66,  67,  69,  70,  71,  72,  73,  74,\n",
        "        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
        "        88,  89,  90,  91,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
        "       102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
        "       116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129,\n",
        "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143,\n",
        "       144, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157]), array([  0,  18,  21,  24,  26,  27,  44,  62,  64,  68,  92, 103, 123,\n",
        "       141, 145, 150]))\n",
        "(array([  0,   1,   2,   3,   4,   5,   7,   9,  10,  11,  12,  13,  14,\n",
        "        16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
        "        29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
        "        42,  43,  44,  48,  49,  51,  52,  53,  54,  55,  56,  57,  58,\n",
        "        59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
        "        72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
        "        85,  86,  87,  88,  89,  90,  91,  92,  94,  95,  97, 100, 101,\n",
        "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
        "       115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130,\n",
        "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
        "       144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156]), array([  6,   8,  15,  45,  46,  47,  50,  93,  96,  98,  99, 116, 119,\n",
        "       124, 153, 157]))\n",
        "(array([  0,   2,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,  14,\n",
        "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
        "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  39,  40,  41,\n",
        "        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  54,  55,\n",
        "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
        "        69,  70,  71,  72,  73,  76,  77,  78,  81,  82,  83,  84,  86,\n",
        "        88,  89,  90,  92,  93,  94,  96,  97,  98,  99, 100, 101, 102,\n",
        "       103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 116, 117,\n",
        "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
        "       131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
        "       145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157]), array([  1,   9,  38,  53,  74,  75,  79,  80,  85,  87,  91,  95, 110,\n",
        "       115, 132, 154]))\n",
        "(array([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  14,\n",
        "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
        "        28,  29,  30,  32,  33,  34,  35,  36,  37,  38,  39,  41,  43,\n",
        "        44,  45,  46,  47,  48,  49,  50,  52,  53,  54,  55,  56,  57,\n",
        "        59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  72,  73,\n",
        "        74,  75,  76,  77,  79,  80,  81,  82,  83,  85,  86,  87,  88,\n",
        "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
        "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116,\n",
        "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
        "       130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143,\n",
        "       145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157]), array([  5,  13,  31,  40,  42,  51,  58,  70,  71,  78,  84,  89, 113,\n",
        "       138, 144, 152]))\n",
        "(array([  0,   1,   2,   3,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "        15,  16,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,\n",
        "        30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
        "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  56,  57,\n",
        "        58,  59,  61,  62,  63,  64,  65,  68,  69,  70,  71,  72,  73,\n",
        "        74,  75,  76,  77,  78,  79,  80,  81,  82,  84,  85,  87,  88,\n",
        "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
        "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
        "       116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
        "       130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
        "       145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157]), array([  4,  14,  17,  23,  54,  55,  60,  66,  67,  83,  86, 102, 118,\n",
        "       133, 135, 148]))\n",
        "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "        14,  15,  16,  17,  18,  19,  21,  22,  23,  24,  25,  26,  27,\n",
        "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
        "        41,  42,  44,  45,  46,  47,  48,  50,  51,  53,  54,  55,  56,\n",
        "        57,  58,  59,  60,  62,  64,  65,  66,  67,  68,  70,  71,  72,\n",
        "        74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
        "        87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  98,  99, 100,\n",
        "       101, 102, 103, 104, 105, 107, 108, 109, 110, 113, 114, 115, 116,\n",
        "       117, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
        "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145,\n",
        "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157]), array([ 10,  20,  43,  49,  52,  61,  63,  69,  73,  97, 106, 111, 112,\n",
        "       120, 121, 143]))\n",
        "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
        "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
        "        26,  27,  29,  30,  31,  32,  34,  35,  36,  37,  38,  40,  41,\n",
        "        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
        "        55,  56,  57,  58,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
        "        69,  70,  71,  72,  73,  74,  75,  76,  78,  79,  80,  81,  82,\n",
        "        83,  84,  85,  86,  87,  88,  89,  91,  92,  93,  94,  95,  96,\n",
        "        97,  98,  99, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111,\n",
        "       112, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
        "       127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142,\n",
        "       143, 144, 145, 148, 149, 150, 151, 152, 153, 154, 156, 157]), array([ 28,  33,  39,  59,  77,  90, 104, 105, 114, 117, 128, 129, 140,\n",
        "       146, 147, 155]))\n",
        "(array([  0,   1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
        "        14,  15,  17,  18,  20,  21,  23,  24,  25,  26,  27,  28,  29,\n",
        "        30,  31,  32,  33,  35,  37,  38,  39,  40,  41,  42,  43,  44,\n",
        "        45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,\n",
        "        59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
        "        72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
        "        85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,  97,  98,\n",
        "        99, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113,\n",
        "       114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
        "       128, 129, 130, 132, 133, 135, 137, 138, 139, 140, 141, 143, 144,\n",
        "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157]), array([  3,  16,  19,  22,  34,  36,  57,  94, 107, 109, 127, 131, 134,\n",
        "       136, 142]))\n",
        "(array([  0,   1,   3,   4,   5,   6,   8,   9,  10,  12,  13,  14,  15,\n",
        "        16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
        "        30,  31,  32,  33,  34,  36,  38,  39,  40,  41,  42,  43,  44,\n",
        "        45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  57,  58,\n",
        "        59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
        "        73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
        "        86,  87,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "       100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114,\n",
        "       115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128,\n",
        "       129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143,\n",
        "       144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157]), array([  2,   7,  11,  29,  35,  37,  56,  72,  88, 101, 108, 126, 130,\n",
        "       137, 151]))\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "REGRESSION"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "10 Article"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w = xlsxwriter.Workbook('regression.xls')\n",
      "ws = w.add_worksheet()\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "for y in range(-10,5):\n",
      "    offset_day = y\n",
      "    wiki_weekly_list = get_wiki_data(offset_day)\n",
      "    wiki_mult_list = []\n",
      "    \n",
      "    for x in range(len(wiki_weekly_list)):\n",
      "        temp = []\n",
      "        for i in top10_article_name:\n",
      "            temp.append(wiki_weekly_list[i][x])\n",
      "        wiki_mult_list.append(temp)\n",
      "        \n",
      "        \n",
      "    #wiki_groundtruth_list.append(ground_truth_data[1])\n",
      "    wiki_multiple_list = np.asarray(wiki_mult_list)\n",
      "    normalized_wiki_data = Normalization(wiki_multiple_list)\n",
      "    \n",
      "    \n",
      "    results = []\n",
      "    \n",
      "    results.append(offset_day)\n",
      "    \n",
      "    '''\n",
      "    s = ScikitRegression(normalized_wiki_data, mylist)\n",
      "    for i in s:\n",
      "        results.append(i)\n",
      "    \n",
      "    o = OLS(normalized_wiki_data, mylist)\n",
      "    results.append(o)\n",
      "    \n",
      "    g = GridSearch(normalized_wiki_data, mylist)\n",
      "    for i in g:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    '''\n",
      "    l = Lasso(normalized_wiki_data, mylist)\n",
      "    for i in l:\n",
      "        results.append(i)\n",
      "\n",
      "    \n",
      "    lg = LassoGrid(normalized_wiki_data, mylist)\n",
      "    for i in lg:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    \n",
      "    '''\n",
      "    r = Ridge(normalized_wiki_data, mylist)\n",
      "    for i in r:\n",
      "        results.append(i)\n",
      "        \n",
      "    rg = RidgeGrid(normalized_wiki_data, mylist)\n",
      "    for i in rg:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    e = Elastic(normalized_wiki_data, mylist)\n",
      "    for i in e:\n",
      "        results.append(i)\n",
      "    \n",
      "    eg = ElasticGrid(normalized_wiki_data, mylist)\n",
      "    for i in eg:\n",
      "        results.append(i)\n",
      "        \n",
      "    %cd /home/bbardak/Desktop/gft_wiki/\n",
      "   \n",
      "    col = 0\n",
      "    for i in results:\n",
      "        ws.write(row, col, i)\n",
      "        col = col + 1\n",
      "    row = row + 1\n",
      "w.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-22 00:00:00  Ending Day :  2013-12-31 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n",
        "/usr/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:553: DeprecationWarning: rho was renamed to l1_ratio and will be removed in 0.15\n",
        "  \"in 0.15\", DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "20 State"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w = xlsxwriter.Workbook('regression.xls')\n",
      "ws = w.add_worksheet()\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "for y in range(-2,2):\n",
      "    \n",
      "    offset_week = y\n",
      "    gft_list = get_gft_data(offset_week)\n",
      "    \n",
      "    gft20_mult_list = []\n",
      "    \n",
      "    for x in range(len(gft_list)):\n",
      "        temp = []\n",
      "        for i in top20_state_name:\n",
      "            temp.append(gft_list[i][x])\n",
      "        gft20_mult_list.append(temp)\n",
      "        \n",
      "    gft20_mult_list = np.asarray(gft20_mult_list)    \n",
      "    normalized_gft20_data = Normalization(gft20_mult_list)\n",
      "    \n",
      "    \n",
      "    results = []\n",
      "    \n",
      "    results.append(offset_week)\n",
      "    '''\n",
      "    s = ScikitRegression(normalized_gft20_data, mylist)\n",
      "    for i in s:\n",
      "        results.append(i)\n",
      "    \n",
      "    o = OLS(normalized_gft20_data, mylist)\n",
      "    results.append(o)\n",
      "    \n",
      "    g = GridSearch(normalized_gft20_data, mylist)\n",
      "    for i in g:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    '''\n",
      "    l = Lasso(normalized_gft20_data, mylist)\n",
      "    for i in l:\n",
      "        results.append(i)\n",
      "\n",
      "    \n",
      "    lg = LassoGrid(normalized_gft20_data, mylist)\n",
      "    for i in lg:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    '''\n",
      "    r = Ridge(normalized_gft20_data, mylist)\n",
      "    for i in r:\n",
      "        results.append(i)\n",
      "        \n",
      "    rg = RidgeGrid(normalized_gft20_data, mylist)\n",
      "    for i in rg:\n",
      "        results.append(i)\n",
      "    '''    \n",
      "        \n",
      "    %cd /home/bbardak/Desktop/gft_wiki/\n",
      "   \n",
      "    col = 0\n",
      "    for i in results:\n",
      "        ws.write(row, col, i)\n",
      "        col = col + 1\n",
      "    row = row + 1\n",
      "w.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n"
       ]
      }
     ],
     "prompt_number": 211
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "30 State"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w = xlsxwriter.Workbook('regression.xls')\n",
      "ws = w.add_worksheet()\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "for y in range(-2,2):\n",
      "    \n",
      "    offset_week = y\n",
      "    gft_list = get_gft_data(offset_week)\n",
      "    \n",
      "    gft30_mult_list = []\n",
      "    \n",
      "    for x in range(len(gft_list)):\n",
      "        temp = []\n",
      "        for i in top30_state_name:\n",
      "            temp.append(gft_list[i][x])\n",
      "        gft30_mult_list.append(temp)\n",
      "        \n",
      "    gft30_mult_list = np.asarray(gft30_mult_list)\n",
      "    normalized_gft30_data = Normalization(gft30_mult_list)\n",
      "    \n",
      "    \n",
      "    results = []\n",
      "    \n",
      "    results.append(offset_week)\n",
      "    \n",
      "    '''\n",
      "    s = ScikitRegression(normalized_gft30_data, mylist)\n",
      "    for i in s:\n",
      "        results.append(i)\n",
      "    \n",
      "    o = OLS(normalized_gft30_data, mylist)\n",
      "    results.append(o)\n",
      "    \n",
      "    g = GridSearch(normalized_gft30_data, mylist)\n",
      "    for i in g:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    '''\n",
      "    l = Lasso(normalized_gft30_data, mylist)\n",
      "    for i in l:\n",
      "        results.append(i)\n",
      "\n",
      "    \n",
      "    lg = LassoGrid(normalized_gft30_data, mylist)\n",
      "    for i in lg:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    \n",
      "    r = Ridge(normalized_gft30_data, mylist)\n",
      "    for i in r:\n",
      "        results.append(i)\n",
      "        \n",
      "    rg = RidgeGrid(normalized_gft30_data, mylist)\n",
      "    for i in rg:\n",
      "        results.append(i)\n",
      "        \n",
      "    %cd /home/bbardak/Desktop/gft_wiki/\n",
      "   \n",
      "    col = 0\n",
      "    for i in results:\n",
      "        ws.write(row, col, i)\n",
      "        col = col + 1\n",
      "    row = row + 1\n",
      "w.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': True, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.5, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "10 Article & 20 State"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w = xlsxwriter.Workbook('regression.xls')\n",
      "ws = w.add_worksheet()\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "for y in range(-10,5):\n",
      "    offset_week = 1\n",
      "    gft_list = get_gft_data(offset_week)\n",
      "    \n",
      "    offset_day = y\n",
      "    wiki_weekly_list = get_wiki_data(offset_day)\n",
      "    \n",
      "    wiki10_gft20_mult_list = []\n",
      "    \n",
      "    counter = 0  ## first 10 is article, bigger than 10 goes to states\n",
      "    \n",
      "    for y in range (len(wiki_weekly_list)):\n",
      "        temp = []\n",
      "        counter = 0\n",
      "        for i in top10_article_20state_names:\n",
      "            counter = counter + 1\n",
      "            if counter < 11:\n",
      "                temp.append(wiki_weekly_list[i][y])\n",
      "            else:\n",
      "                temp.append(gft_list[i][y])\n",
      "        wiki10_gft20_mult_list.append(temp)\n",
      "    \n",
      "        \n",
      "    wiki10_gft20_mult_list = np.asarray(wiki10_gft20_mult_list)\n",
      "    normalized_wiki10_gft20_data = Normalization(wiki10_gft20_mult_list)\n",
      "\n",
      "    results = []\n",
      "    results.append(offset_day)\n",
      "    \n",
      "    \n",
      "    s = ScikitRegression(normalized_wiki10_gft20_data, mylist)\n",
      "    for i in s:\n",
      "        results.append(i)\n",
      "    \n",
      "    o = OLS(normalized_wiki10_gft20_data, mylist)\n",
      "    results.append(o)\n",
      "    \n",
      "    g = GridSearch(normalized_wiki10_gft20_data, mylist)\n",
      "    for i in g:\n",
      "        results.append(i)\n",
      "    \n",
      "    '''\n",
      "    l = Lasso(normalized_wiki10_gft20_data, mylist)\n",
      "    for i in l:\n",
      "        results.append(i)\n",
      "\n",
      "    \n",
      "    lg = LassoGrid(normalized_wiki10_gft20_data, mylist)\n",
      "    for i in lg:\n",
      "        results.append(i)\n",
      "    '''   \n",
      "    \n",
      "    '''\n",
      "    r = Ridge(normalized_wiki10_gft20_data, mylist)\n",
      "    for i in r:\n",
      "        results.append(i)\n",
      "        \n",
      "    rg = RidgeGrid(normalized_wiki10_gft20_data, mylist)\n",
      "    for i in rg:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    \n",
      "    %cd /home/bbardak/Desktop/gft_wiki/\n",
      "   \n",
      "    col = 0\n",
      "    for i in results:\n",
      "        ws.write(row, col, i)\n",
      "        col = col + 1\n",
      "    row = row + 1\n",
      "w.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-22 00:00:00  Ending Day :  2013-12-31 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-23 00:00:00  Ending Day :  2014-01-01 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-24 00:00:00  Ending Day :  2014-01-02 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-25 00:00:00  Ending Day :  2014-01-03 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-26 00:00:00  Ending Day :  2014-01-04 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-27 00:00:00  Ending Day :  2014-01-05 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-28 00:00:00  Ending Day :  2014-01-06 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-29 00:00:00  Ending Day :  2014-01-07 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-30 00:00:00  Ending Day :  2014-01-08 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-31 00:00:00  Ending Day :  2014-01-09 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-01 00:00:00  Ending Day :  2014-01-10 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-02 00:00:00  Ending Day :  2014-01-11 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-03 00:00:00  Ending Day :  2014-01-12 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-04 00:00:00  Ending Day :  2014-01-13 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-05 00:00:00  Ending Day :  2014-01-14 24:00:00\n",
        "/home/bbardak/Desktop/gft_wiki"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 224
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "10 Article & 30 State"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w = xlsxwriter.Workbook('regression.xls')\n",
      "ws = w.add_worksheet()\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "for y in range(-10,5):\n",
      "    offset_week = 1\n",
      "    gft_list = get_gft_data(offset_week)\n",
      "    \n",
      "    offset_day = y\n",
      "    wiki_weekly_list = get_wiki_data(offset_day)\n",
      "    \n",
      "    wiki10_gft30_mult_list = []\n",
      "    \n",
      "    counter = 0  ## first 10 is article, bigger than 10 goes to states\n",
      "    \n",
      "    for y in range (len(wiki_weekly_list)):\n",
      "        temp = []\n",
      "        counter = 0\n",
      "        for i in top10_article_30state_names:\n",
      "            counter = counter + 1\n",
      "            if counter < 11:\n",
      "                temp.append(wiki_weekly_list[i][y])\n",
      "            else:\n",
      "                temp.append(gft_list[i][y])\n",
      "        wiki10_gft30_mult_list.append(temp)\n",
      "    \n",
      "        \n",
      "    wiki10_gft30_mult_list = np.asarray(wiki10_gft30_mult_list)\n",
      "    normalized_wiki10_gft30_data = Normalization(wiki10_gft30_mult_list)\n",
      "\n",
      "    results = []\n",
      "    results.append(offset_day)\n",
      "    \n",
      "    '''\n",
      "    s = ScikitRegression(normalized_wiki10_gft30_data, mylist)\n",
      "    for i in s:\n",
      "        results.append(i)\n",
      "    \n",
      "    o = OLS(normalized_wiki10_gft30_data, mylist)\n",
      "    results.append(o)\n",
      "    \n",
      "    g = GridSearch(normalized_wiki10_gft30_data, mylist)\n",
      "    for i in g:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    '''\n",
      "    l = Lasso(normalized_wiki10_gft30_data, mylist)\n",
      "    for i in l:\n",
      "        results.append(i)\n",
      "\n",
      "    \n",
      "    lg = LassoGrid(normalized_wiki10_gft30_data, mylist)\n",
      "    for i in lg:\n",
      "        results.append(i)\n",
      "    '''\n",
      "    \n",
      "    r = Ridge(normalized_wiki10_gft30_data, mylist)\n",
      "    for i in r:\n",
      "        results.append(i)\n",
      "        \n",
      "    rg = RidgeGrid(normalized_wiki10_gft30_data, mylist)\n",
      "    for i in rg:\n",
      "        results.append(i)\n",
      "        \n",
      "    %cd /home/bbardak/Desktop/gft_wiki/\n",
      "   \n",
      "    col = 0\n",
      "    for i in results:\n",
      "        ws.write(row, col, i)\n",
      "        col = col + 1\n",
      "    row = row + 1\n",
      "w.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-22 00:00:00  Ending Day :  2013-12-31 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-23 00:00:00  Ending Day :  2014-01-01 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-24 00:00:00  Ending Day :  2014-01-02 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-25 00:00:00  Ending Day :  2014-01-03 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-26 00:00:00  Ending Day :  2014-01-04 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-27 00:00:00  Ending Day :  2014-01-05 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-28 00:00:00  Ending Day :  2014-01-06 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-29 00:00:00  Ending Day :  2014-01-07 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-30 00:00:00  Ending Day :  2014-01-08 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2010-12-31 00:00:00  Ending Day :  2014-01-09 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-01 00:00:00  Ending Day :  2014-01-10 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-02 00:00:00  Ending Day :  2014-01-11 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.1, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-03 00:00:00  Ending Day :  2014-01-12 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.5, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-04 00:00:00  Ending Day :  2014-01-13 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.5, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data\n",
        "/home/bbardak/Desktop/gft_wiki/S1_supplemental-data/wiki-data\n",
        "Beginning day :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2011-01-05 00:00:00  Ending Day :  2014-01-14 24:00:00\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'normalize': False, 'alpha': 0.5, 'max_iter': 1, 'fit_intercept': True}\n",
        "/home/bbardak/Desktop/gft_wiki\n"
       ]
      }
     ],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ScikitRegression(data, kf_list):\n",
      "    \n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "        \n",
      "        #print X_train, y_train\n",
      "        #print X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
      "        \n",
      "        model = linear_model.LinearRegression()\n",
      "        model.fit(X_train, y_train)\n",
      "        predictions = model.predict(X_test)\n",
      "\n",
      "        score = score + model.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "    \n",
      "    list_of_results = []\n",
      "    score = score *1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    \n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def OLS(data, kf_list):\n",
      "    \n",
      "    score = 0    \n",
      "\n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "        \n",
      "        #print X_train, y_train\n",
      "        #print X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
      "        \n",
      "        x_train = sm.add_constant(X_train)\n",
      "        model = sm.OLS(y_train, x_train)\n",
      "        results = model.fit()\n",
      "        \n",
      "        #x_test = sm.add_constant(X_test)\n",
      "        \n",
      "        score = score + results.rsquared\n",
      "    score = score * 1.0 / 10\n",
      "    return score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GridSearch(data, kf_list):\n",
      "    \n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "        \n",
      "        #print X_train, y_train\n",
      "        #print X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
      "        \n",
      "        parameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\n",
      "        model = linear_model.LinearRegression(fit_intercept=True,normalize=True, copy_X=True)\n",
      "        grid = GridSearchCV(model,parameters,cv=10)\n",
      "        \n",
      "        grid.fit(X_train, y_train)\n",
      "        predictions = grid.predict(X_test)\n",
      "\n",
      "        score = score + grid.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "    \n",
      "    list_of_results = []\n",
      "    score = score *1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    \n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.LinearRegression()\n",
      "\n",
      "b = cross_validation.cross_val_score(model, normalized_wiki_data, ground_truth_data, scoring='mean_squared_error', cv=kf, n_jobs = 1)\n",
      "c = cross_validation.cross_val_score(model, normalized_wiki_data, ground_truth_data, scoring='r2', cv=kf, n_jobs = 1)\n",
      "\n",
      "sum = 0\n",
      "for i in b:\n",
      "    sum = sum + i\n",
      "print sum / 10\n",
      "\n",
      "sum = 0\n",
      "for i in c:\n",
      "    sum = sum + i\n",
      "print sum / 10\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "LASSO"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Lasso(data, kf_list):\n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "            \n",
      "        model = linear_model.Lasso(alpha=0.1)\n",
      "        model.fit(X_train, y_train)\n",
      "    \n",
      "        predictions = model.predict(X_test)\n",
      "    \n",
      "        score = score + model.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "\n",
      "    list_of_results = []\n",
      "    \n",
      "    score = score *1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    \n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def LassoGrid(data, kf_list):\n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "        \n",
      "        ll = []\n",
      "        for i in seq(0, 1, 0.1):\n",
      "            ll.append(i)\n",
      "            \n",
      "        parameters = {'alpha': [0.1,0.5,1],'fit_intercept':[True,False], 'normalize':[True,False], 'max_iter':[1,10,100,1000]}    \n",
      "        model = linear_model.Lasso()\n",
      "        \n",
      "        grid = GridSearchCV(model,parameters,cv=10, n_jobs=-1)\n",
      "        grid.fit(X_train, y_train)\n",
      "        predictions = grid.predict(X_test)\n",
      "       \n",
      "        score = score + grid.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "        \n",
      "    list_of_results = []\n",
      "        \n",
      "    score = score * 1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    print grid.best_params_\n",
      "\n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "RIDGE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Ridge(data, kf_list):\n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "            \n",
      "        model = linear_model.Lasso(alpha=0.1)\n",
      "        model.fit(X_train, y_train)\n",
      "    \n",
      "        predictions = model.predict(X_test)\n",
      "    \n",
      "        score = score + model.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "\n",
      "    list_of_results = []\n",
      "    \n",
      "    score = score *1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    \n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def RidgeGrid(data, kf_list):\n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "        \n",
      "        ll = []\n",
      "        for i in seq(0, 1, 0.1):\n",
      "            ll.append(i)\n",
      "            \n",
      "        parameters = {'alpha': [0.1,0.5,1],'fit_intercept':[True,False], 'normalize':[True,False], 'max_iter':[1,10,100,1000]}    \n",
      "        model = linear_model.Ridge()\n",
      "        \n",
      "        grid = GridSearchCV(model,parameters,cv=10, n_jobs=-1)\n",
      "        grid.fit(X_train, y_train)\n",
      "        predictions = grid.predict(X_test)\n",
      "       \n",
      "        score = score + grid.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "        \n",
      "    list_of_results = []\n",
      "        \n",
      "    score = score * 1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    print grid.best_params_\n",
      "\n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ELASTIC NET "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Elastic(data, kf_list):\n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "            \n",
      "        model = linear_model.ElasticNet(alpha=0.1, l1_ratio=0.7)\n",
      "        model.fit(X_train, y_train)\n",
      "    \n",
      "        predictions = model.predict(X_test)\n",
      "    \n",
      "        score = score + model.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "\n",
      "    list_of_results = []\n",
      "    \n",
      "    score = score *1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    \n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ElasticGrid(data, kf_list):\n",
      "    score = 0\n",
      "    mse = 0\n",
      "    mae = 0\n",
      "    \n",
      "    for train,test in kf_list:\n",
      "        xtr = [] # X_train data\n",
      "        xte = [] # X_test data\n",
      "            \n",
      "        ytr = [] # y_train data\n",
      "        yte = [] # y_test data\n",
      "        for i in train:\n",
      "            xtr.append(data[i])\n",
      "            ytr.append(ground_truth_data[i])\n",
      "        for y in test:\n",
      "            xte.append(data[y])\n",
      "            yte.append(ground_truth_data[y])\n",
      "        \n",
      "        X_train = np.asarray(xtr)    \n",
      "        X_test = np.asarray(xte)\n",
      "        y_train = np.asarray(ytr)\n",
      "        y_test = np.asarray(yte)\n",
      "        \n",
      "        ll = []\n",
      "        for i in seq(0, 1, 0.1):\n",
      "            ll.append(i)\n",
      "            \n",
      "        parameters = {'alpha': [0.1,0.5,1],'fit_intercept':[True,False], 'normalize':[True,False],'l1_ratio':[0.1,0.5,0.7,1]}    \n",
      "        model = linear_model.ElasticNet()\n",
      "        \n",
      "        grid = GridSearchCV(model,parameters,cv=10, n_jobs=-1)\n",
      "        grid.fit(X_train, y_train)\n",
      "        predictions = grid.predict(X_test)\n",
      "       \n",
      "        score = score + grid.score(X_test,y_test)\n",
      "        mse = mse + mean_squared_error(y_test, predictions)\n",
      "        mae = mae + mean_absolute_error(y_test, predictions)\n",
      "        \n",
      "    list_of_results = []\n",
      "        \n",
      "    score = score * 1.0 / 10\n",
      "    mse = mse * 1.0 / 10\n",
      "    mae = mae * 1.0 / 10\n",
      "    list_of_results.append(score)\n",
      "    list_of_results.append(mse)\n",
      "    list_of_results.append(mae)\n",
      "    print grid.best_params_\n",
      "\n",
      "    return list_of_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}